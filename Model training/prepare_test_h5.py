# -*- coding: utf-8 -*-
"""
prepare_test_h5.py
- ìŠ¬ë¼ì´ë“œ ì´ë¯¸ì§€(WSI ë“±)ë¥¼ ì…ë ¥ë°›ì•„ í•™ìŠµìš© HDF5 íŒŒì¼(.h5)ë¡œ ë³€í™˜í•˜ëŠ” ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸.
- ì£¼ìš” ë‹¨ê³„:
  1) ë°°ê²½ í•„í„°ë§: ì§€ë‚˜ì¹˜ê²Œ ê²€ì€/í° íŒ¨ì¹˜ ì œê±°
  2) íŒ¨ì¹˜ ë¶„í• : ì›ë³¸ ì´ë¯¸ì§€ë¥¼ PATCH_SIZE ë‹¨ìœ„ë¡œ ìŠ¬ë¼ì´ì‹±
  3) íŠ¹ì§• ì¶”ì¶œ: ResNet18 ì‚¬ì „í•™ìŠµ ëª¨ë¸ë¡œ feature vector ìƒì„±
  4) ìµœê·¼ì ‘ íŒ¨ì¹˜ ê³„ì‚°: ê³µê°„ì ìœ¼ë¡œ ì¸ì ‘í•œ íŒ¨ì¹˜ë“¤ ê°„ ì¸ë±ìŠ¤ ë§¤í•‘
  5) HDF5 ì €ì¥: features, coords, nearest ì„¸ ê°€ì§€ë¥¼ datasetìœ¼ë¡œ ê¸°ë¡
"""

import os
import numpy as np
import h5py
from PIL import Image
from torchvision import models, transforms
import torch
from tqdm import tqdm

# ------------------------------
# ì „ì—­ ì„¤ì •ê°’
# ------------------------------
PATCH_SIZE = 256                # íŒ¨ì¹˜ í¬ê¸°(px ë‹¨ìœ„)
BLACK_THRESHOLD = 0.95           # ì „ì²´ í”½ì…€ ì¤‘ 95% ì´ìƒì´ ê²€ìœ¼ë©´ ë°°ê²½ìœ¼ë¡œ ê°„ì£¼
WHITE_THRESHOLD = 0.99           # ì „ì²´ í”½ì…€ ì¤‘ 99% ì´ìƒì´ í°ìƒ‰ì´ë©´ ë°°ê²½ìœ¼ë¡œ ê°„ì£¼
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ------------------------------
# Feature extractor ëª¨ë¸ (ResNet18)
# - ImageNet pretrained
# - ë§ˆì§€ë§‰ FC layer ì œê±° â†’ 512-dim feature vector ì¶œë ¥
# ------------------------------
resnet = models.resnet18(pretrained=True)
resnet = torch.nn.Sequential(*list(resnet.children())[:-1])  # ë§ˆì§€ë§‰ FC ì œê±°
resnet.eval().to(device)

# ì´ë¯¸ì§€ ë³€í™˜ íŒŒì´í”„ë¼ì¸
transform = transforms.Compose([
    transforms.Resize((224, 224)),   # ResNet ì…ë ¥ í¬ê¸°
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],   # ImageNet mean
                         [0.229, 0.224, 0.225]), # ImageNet std
])

# ===========================================================
# 1) ë°°ê²½ í•„í„°ë§ í•¨ìˆ˜
# ===========================================================
def is_black(patch):
    """
    Args:
        patch (np.ndarray): íŒ¨ì¹˜ ì´ë¯¸ì§€ ë°°ì—´
    Returns:
        bool: ëŒ€ë¶€ë¶„ ê²€ì€ìƒ‰ì¸ ê²½ìš° True
    """
    return np.mean(patch <= 10) >= BLACK_THRESHOLD

def is_white(patch):
    """
    Args:
        patch (np.ndarray): íŒ¨ì¹˜ ì´ë¯¸ì§€ ë°°ì—´
    Returns:
        bool: ëŒ€ë¶€ë¶„ í°ìƒ‰ì¸ ê²½ìš° True
    """
    return np.mean(patch >= 245) >= WHITE_THRESHOLD


# ===========================================================
# 2) íŒ¨ì¹˜ ìƒì„± (ì´ë¯¸ì§€ ìŠ¬ë¼ì´ì‹± í›„ ë°˜í™˜)
# ===========================================================
def generate_patches(image_path):
    """
    Args:
        image_path (str): ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
    Returns:
        patches (List[PIL.Image.Image]): ì „ì²˜ë¦¬ëœ íŒ¨ì¹˜ë“¤
        coords  (np.ndarray): ê° íŒ¨ì¹˜ì˜ ì¢Œí‘œ (x, y)
    """
    patches, coords = [], []
    img = Image.open(image_path).convert("RGB")
    img_np = np.array(img)
    h, w = img_np.shape[:2]

    for y in range(0, h, PATCH_SIZE):
        for x in range(0, w, PATCH_SIZE):
            patch = img_np[y:y+PATCH_SIZE, x:x+PATCH_SIZE]

            # ê²½ê³„ì— ê±¸ì³ íŒ¨ì¹˜ í¬ê¸°ê°€ ëª¨ìë€ ê²½ìš° skip
            if patch.shape[:2] != (PATCH_SIZE, PATCH_SIZE):
                continue

            # ë°°ê²½(ê²€ì •/í°ìƒ‰) íŒ¨ì¹˜ëŠ” skip
            if is_black(patch) or is_white(patch):
                continue

            patches.append(Image.fromarray(patch))
            coords.append([x, y])

    return patches, np.array(coords)


# ===========================================================
# 3) íŠ¹ì§• ì¶”ì¶œ
# ===========================================================
def extract_features(patches):
    """
    Args:
        patches (List[PIL.Image.Image]): íŒ¨ì¹˜ ì´ë¯¸ì§€ë“¤
    Returns:
        np.ndarray: shape (num_patches, 512) feature ë²¡í„°
    """
    feats = []
    for p in patches:
        inp = transform(p).unsqueeze(0).to(device)
        with torch.no_grad():
            feat = resnet(inp).squeeze().cpu().numpy()
        feats.append(feat)
    return np.array(feats)


# ===========================================================
# 4) ìµœê·¼ì ‘ ì¢Œí‘œ ê³„ì‚°
# ===========================================================
def compute_nearest(coords):
    """
    Args:
        coords (np.ndarray): shape (N, 2) ê° íŒ¨ì¹˜ì˜ (x, y) ì¢Œí‘œ
    Returns:
        np.ndarray: shape (N, 9), ê° íŒ¨ì¹˜ì˜ ìµœê·¼ì ‘ ì´ì›ƒ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
                    (ìì‹  í¬í•¨ + ì£¼ë³€ 8ë°©í–¥)
    """
    nearest = []
    for i, p in enumerate(coords):
        neighbors = [i]  # ìê¸° ìì‹  í¬í•¨
        for dx in [-1, 0, 1]:
            for dy in [-1, 0, 1]:
                if dx == dy == 0:
                    continue
                neighbor = p + np.array([dx * PATCH_SIZE, dy * PATCH_SIZE])
                idx = np.where(np.all(coords == neighbor, axis=1))[0]
                neighbors.append(idx[0] if len(idx) > 0 else i)  # ì—†ìœ¼ë©´ ìê¸° ìì‹ 
        nearest.append(neighbors)
    return np.array(nearest)


# ===========================================================
# 5) ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# ===========================================================
def preprocess_slide(image_path, save_path, label, image_id):
    """
    Args:
        image_path (str): ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
        save_path (str): .h5 ì €ì¥ ê²½ë¡œ
        label (str): ë¼ë²¨ëª… (ex: 'CC', 'HGSC')
        image_id (str|int): ìƒ˜í”Œ ID
    Returns:
        None (HDF5 íŒŒì¼ ìƒì„±)
    """
    print(f"ğŸ“„ ì²˜ë¦¬ ì¤‘: {image_id}")

    # (1) íŒ¨ì¹˜ ìƒì„±
    patches, coords = generate_patches(image_path)
    if len(patches) == 0:
        print("âš ï¸ ìœ íš¨í•œ íŒ¨ì¹˜ ì—†ìŒ")
        return

    # (2) íŠ¹ì§• ì¶”ì¶œ
    features = extract_features(patches)

    # (3) ìµœê·¼ì ‘ ì´ì›ƒ ê³„ì‚°
    nearest = compute_nearest(coords)

    # (4) ì €ì¥
    os.makedirs(save_path, exist_ok=True)
    h5_name = f"{label}_{image_id}.h5"
    with h5py.File(os.path.join(save_path, h5_name), 'w') as h5:
        h5.create_dataset('features', data=features)  # (N, 512)
        h5.create_dataset('coords', data=coords)      # (N, 2)
        h5.create_dataset('nearest', data=nearest)    # (N, 9)

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {h5_name} | features: {features.shape}, coords: {coords.shape}, nearest: {nearest.shape}")
