# -*- coding: utf-8 -*-
"""
preprocessing_pipeline.py
- ì›ë³¸ ZIP ë°ì´í„° â†’ JPG ë³€í™˜ â†’ íŒ¨ì¹˜ ìƒì„± â†’ íŠ¹ì§• ì¶”ì¶œ â†’ ìµœê·¼ì ‘ ì´ì›ƒ ê³„ì‚° â†’ ìµœì¢… h5 ë³‘í•©ê¹Œì§€ ìˆ˜í–‰í•˜ëŠ” ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
"""

import os
import zipfile
import io
import random
import numpy as np
import pandas as pd
from PIL import Image, ImageFile
from tqdm import tqdm
import imageio.v3 as iio

import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

# pngíŒŒì¼ì´ ë„ˆë¬´ ì»¤ì„œ ë¡œì»¬í™˜ê²½ì—ì„œ í•™ìŠµë¶ˆê°€ â†’ jpgë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥

# ====== íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬ =======
def image_exists(image_id, label):
    # ì €ì¥ëœ í™•ì¥ì .jpgë¡œ í†µì¼í•˜ì—¬ í™•ì¸
    return os.path.exists(os.path.join(output_base_dir, label, f"{image_id}.jpg"))

# ====== ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (í¬ë©´ ì¤„ì„) =======
def resize_if_needed(img, image_id):
    width, height = img.size
    # MAX_DIMë³´ë‹¤ í¬ë©´ ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
    if width > MAX_DIM or height > MAX_DIM:
        scale = min(MAX_DIM / width, MAX_DIM / height)
        new_size = (int(width * scale), int(height * scale))
        img = img.resize(new_size, Image.LANCZOS)
        tqdm.write(f"ğŸ”„ Resized {image_id} from ({width},{height}) to {new_size}")
    return img

# ====== ZIPì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ë° JPGë¡œ ì €ì¥ =======
def extract_and_save(image_id, label, archive):
    target_filename = f"train_images/{image_id}.png"
    # zip ë‚´ í•´ë‹¹ ì´ë¯¸ì§€ ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
    candidates = [f for f in archive.namelist() if f.lower() == target_filename.lower()]
    if not candidates:
        tqdm.write(f"âŒ Not found in ZIP: image_id={image_id}")
        return False
    if len(candidates) > 1:
        tqdm.write(f"âš ï¸ Multiple candidates found for {image_id}: {candidates}, using first one")
    zip_img_path = candidates[0]
    try:
        with archive.open(zip_img_path) as file:
            img = Image.open(io.BytesIO(file.read()))
            img.load()
            img = resize_if_needed(img, image_id)
            img = img.convert("RGB")
            # ì €ì¥ ê²½ë¡œ ìƒì„±
            label_dir = os.path.join(output_base_dir, label)
            os.makedirs(label_dir, exist_ok=True)
            dest_path = os.path.join(label_dir, f"{image_id}.jpg")
            img.save(dest_path, "JPEG", quality=80)
            tqdm.write(f"âœ… Saved: {dest_path}")
            return True
    except Exception as e:
        tqdm.write(f"âš ï¸ Failed to process {image_id}: {e}")
        return False

# PIL ì˜µì…˜ (í° ì´ë¯¸ì§€ í—ˆìš©, ì˜ë¦° ì´ë¯¸ì§€ í—ˆìš©)
Image.MAX_IMAGE_PIXELS = None
ImageFile.LOAD_TRUNCATED_IMAGES = True

# ====== ì„¤ì •ê°’ =======
base_dir = os.path.dirname(__file__)
zip_path = os.path.join(base_dir, "data", "UBC_OCEAN1.zip")
output_base_dir = os.path.join(base_dir, "data", "Data")
csv_path = os.path.join(base_dir, "data", "train.csv")
MAX_DIM = 65000
PATCH_SIZE = 256
BLACK_THRESHOLD = 0.1  # ê²€ì •ìƒ‰ í”½ì…€ ë¹„ìœ¨ ì„ê³„ê°’

# zip ì›ë³¸ png ë°ì´í„°ëŠ” ë³€í™˜ í›„ ì‚­ì œí•˜ì˜€ìŒ

# ====== CSV ê¸°ë°˜ ë°ì´í„° í™•ì¸ =======
df = pd.read_csv(csv_path)

# ====== í´ë˜ìŠ¤ë³„ íŒŒì¼ ìˆ˜ í™•ì¸ =======
label_counts = {}
for label in os.listdir(output_base_dir):
    label_path = os.path.join(output_base_dir, label)
    if os.path.isdir(label_path):
        count = len([f for f in os.listdir(label_path) if f.lower().endswith(".jpg")])
        label_counts[label] = count
label_series = pd.Series(label_counts).sort_values(ascending=False)
print("í´ë”ì— ë‹¤ìš´ë°›ì•„ì§„ íŒŒì¼ ìˆ˜\n", label_series)
print("\nì‹¤ì œ íŒŒì¼ ê°œìˆ˜\n", df['label'].value_counts().rename_axis(None))

# =====================================================
# 1) íŒ¨ì¹˜ ìƒì„± (ë°°ê²½ í•„í„°ë§ í¬í•¨)
# =====================================================
PATCH_SIZE = 256
BLACK_THRESHOLD = 0.95
WHITE_THRESHOLD = 0.99

def is_black_patch(patch, threshold=BLACK_THRESHOLD):
    # íŒ¨ì¹˜ ë‚´ ê²€ì • í”½ì…€ ë¹„ìœ¨ ê³„ì‚°
    black_pixels = np.all(patch <= 10, axis=2)
    black_ratio = np.sum(black_pixels) / (patch.shape[0] * patch.shape[1])
    return black_ratio >= threshold

def is_white_patch(patch, threshold=WHITE_THRESHOLD):
    # íŒ¨ì¹˜ ë‚´ í° í”½ì…€ ë¹„ìœ¨ ê³„ì‚°
    white_pixels = np.all(patch >= 245, axis=2)
    white_ratio = np.sum(white_pixels) / (patch.shape[0] * patch.shape[1])
    return white_ratio >= threshold

def patch_and_save(image_path, save_dir):
    # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ë¡œ ë¶„í• í•˜ì—¬ PNGë¡œ ì €ì¥
    os.makedirs(save_dir, exist_ok=True)
    img = Image.open(image_path).convert("RGB")
    img_np = np.array(img)
    h, w, _ = img_np.shape
    patch_count = 0

    for y in range(0, h, PATCH_SIZE):
        for x in range(0, w, PATCH_SIZE):
            patch = img_np[y:y+PATCH_SIZE, x:x+PATCH_SIZE]
            if patch.shape[0] != PATCH_SIZE or patch.shape[1] != PATCH_SIZE:
                continue
            if is_black_patch(patch) or is_white_patch(patch):
                continue
            patch_img = Image.fromarray(patch)
            patch_filename = f"{os.path.splitext(os.path.basename(image_path))[0]}_patch_{x}_{y}.png"
            patch_img.save(os.path.join(save_dir, patch_filename))
            patch_count += 1

    return patch_count

# =====================================================
# 2) íŠ¹ì§• ì¶”ì¶œ (ResNet18 backbone)
# =====================================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
from torchvision import models
model = models.resnet18(pretrained=True)
model = torch.nn.Sequential(*list(model.children())[:-1])  # ë§ˆì§€ë§‰ FC ì œê±°
model.eval().to(device)

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
img_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225]),
])

def extract_features_from_patch_folder(patch_dir, h5_save_path):
    # íŒ¨ì¹˜ PNGë“¤ì„ ë¶ˆëŸ¬ì™€ feature & ì¢Œí‘œë¥¼ h5ë¡œ ì €ì¥
    features = []
    coords = []

    for fname in tqdm(sorted(os.listdir(patch_dir))):
        if not fname.endswith(".png"):
            continue
        try:
            # íŒŒì¼ëª…ì—ì„œ ì¢Œí‘œ ì¶”ì¶œ
            parts = fname.split("_patch_")[1].split(".")[0].split("_")
            x, y = int(parts[0]), int(parts[1])
        except Exception:
            print(f"âš ï¸ ì¢Œí‘œ ì¶”ì¶œ ì‹¤íŒ¨: {fname}")
            continue

        path = os.path.join(patch_dir, fname)
        img = Image.open(path).convert("RGB")
        img_tensor = img_transform(img).unsqueeze(0).to(device)

        with torch.no_grad():
            feat = model(img_tensor).squeeze().cpu().numpy()

        features.append(feat)
        coords.append([x, y])

    features = np.array(features).squeeze()
    coords = np.array(coords)

    import h5py
    with h5py.File(h5_save_path, 'w') as f:
        f.create_dataset('features', data=features)
        f.create_dataset('coords', data=coords)

    return features.shape, coords.shape

# =====================================================
# 3) ìµœê·¼ì ‘ ì´ì›ƒ(nearest) ê³„ì‚°
# =====================================================
from joblib import Parallel, delayed
import h5py

def find_nearest(input_path, output_path, patch_size=(256, 256)):
    name = os.path.basename(input_path)
    print("ğŸ“‚ ì²˜ë¦¬ ì¤‘:", name)

    h5 = h5py.File(input_path, 'r')
    coords = np.array(h5['coords'])
    h5.close()

    nearest = []

    for step, p in enumerate(coords):
        exists = [step]

        def get_neighbor(offset_x, offset_y):
            neighbor = np.array([p[0] + offset_x, p[1] + offset_y])
            loc = np.where(np.sum(coords == neighbor, axis=1) == 2)[0]
            return loc[0] if len(loc) != 0 else step

        # 8ë°©í–¥ ì´ì›ƒ íƒìƒ‰
        directions = [
            (0, -patch_size[1]), (0, +patch_size[1]),
            (-patch_size[0], 0), (+patch_size[0], 0),
            (-patch_size[0], -patch_size[1]), (+patch_size[0], -patch_size[1]),
            (-patch_size[0], +patch_size[1]), (+patch_size[0], +patch_size[1]),
        ]

        for dx, dy in directions:
            exists.append(get_neighbor(dx, dy))

        nearest.append(exists)

    # nearest ë°°ì—´ì„ h5ì— ì¶”ê°€ ì €ì¥
    with h5py.File(output_path, 'a') as h5:
        h5.create_dataset('nearest', data=nearest)

# =====================================================
# 4) features+coords+nearest ë³‘í•©
# =====================================================
def merge_h5_files(h5_feature_path, h5_with_nearest_path, save_path):
    os.makedirs(save_path, exist_ok=True)

    for name in os.listdir(h5_feature_path):
        if not name.endswith(".h5"):
            continue

        save_file = os.path.join(save_path, name)
        if os.path.exists(save_file):
            print(f"â© ì¡´ì¬í•¨: {name}")
            continue

        print(f"ğŸ”„ ë³‘í•© ì¤‘: {name}")

        # features, coords ë¡œë”©
        with h5py.File(os.path.join(h5_feature_path, name), "r") as h5:
            coords = np.array(h5["coords"])
            features = np.array(h5["features"])

        # nearest ë¡œë”©
        with h5py.File(os.path.join(h5_with_nearest_path, name), "r") as h5:
            nearest = np.array(h5["nearest"])

        # ìµœì¢… ì €ì¥
        with h5py.File(save_file, "w") as h5:
            h5.create_dataset("coords", data=coords)
            h5.create_dataset("features", data=features)
            h5.create_dataset("nearest", data=nearest)

        print(f"âœ… ì €ì¥ ì™„ë£Œ: {save_file} | coords: {coords.shape}, features: {features.shape}, nearest: {nearest.shape}")

# =====================================================
# ë©”ì¸ ì‹¤í–‰ë¶€
# =====================================================
if __name__ == "__main__":
    base_image_dir = os.path.join(base_dir, "data", "Data")  
    patch_base_dir = os.path.join(base_dir, "data", "AttriMIL_DATA", "patches")
    h5_save_dir = os.path.join(base_dir, "data", "AttriMIL_DATA", "h5_files")
    save_path = os.path.join(base_dir, "data", "AttriMIL_DATA", "h5_coords_files")

    os.makedirs(patch_base_dir, exist_ok=True)
    os.makedirs(h5_save_dir, exist_ok=True)
    os.makedirs(save_path, exist_ok=True)

    # ë¼ë²¨ë³„ JPG ì´ë¯¸ì§€ ìˆœíšŒ
    for label in os.listdir(base_image_dir):
        label_path = os.path.join(base_image_dir, label)
        if not os.path.isdir(label_path):
            continue

        print(f"\nğŸ“ ë¼ë²¨ ì²˜ë¦¬ ì¤‘: {label}")
        for fname in os.listdir(label_path):
            if not fname.lower().endswith(".jpg"):
                continue

            slide_id = os.path.splitext(fname)[0]
            image_path = os.path.join(label_path, fname)
            patch_dir = os.path.join(patch_base_dir, label, slide_id)
            h5_path = os.path.join(h5_save_dir, f"{label}_{slide_id}.h5")

            # (a) íŒ¨ì¹˜ ìƒì„±
            if not os.path.exists(patch_dir) or not any(f.endswith(".png") for f in os.listdir(patch_dir)):
                print(f"ğŸ”„ {fname} â†’ íŒ¨ì¹˜ ìƒì„±")
                patch_count = patch_and_save(image_path, patch_dir)
                print(f"âœ… íŒ¨ì¹˜ ìˆ˜: {patch_count}")
                if patch_count == 0:
                    print("âš ï¸ ìœ íš¨í•œ íŒ¨ì¹˜ ì—†ìŒ, ê±´ë„ˆëœ€")
                    continue
            else:
                print(f"â© íŒ¨ì¹˜ ìˆìŒ: {fname}")

            # (b) íŠ¹ì§• ì¶”ì¶œ
            if not os.path.exists(h5_path):
                print(f"ğŸ”„ {fname} â†’ feature ì¶”ì¶œ")
                try:
                    feat_shape, coord_shape = extract_features_from_patch_folder(patch_dir, h5_path)
                    print(f"âœ… ì €ì¥ë¨: {h5_path} | features: {feat_shape}, coords: {coord_shape}")
                except Exception as e:
                    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            else:
                print(f"â© h5 ìˆìŒ: {h5_path}")

    # (c) ìµœê·¼ì ‘ ì´ì›ƒ ê³„ì‚°
    h5_files = [f for f in os.listdir(h5_save_dir) if f.endswith('.h5')]
    print(f"ì´ {len(h5_files)}ê°œì˜ h5 íŒŒì¼ ì²˜ë¦¬ ì˜ˆì •")
    Parallel(n_jobs=8)(delayed(find_nearest)(
        os.path.join(h5_save_dir, fname),
        os.path.join(h5_save_dir, fname),
        (256, 256)
    ) for fname in tqdm(h5_files))

    # (d) ë³‘í•© ì €ì¥
    merge_h5_files(h5_save_dir, h5_save_dir, save_path)
