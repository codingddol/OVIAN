# -*- coding: utf-8 -*-
"""
train_attrimil.py

AttriMIL ê¸°ë°˜ ë‚œì†Œì•” ì¡°ì§ ë¶„ì„ ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë©”ì¸ ì‹¤í–‰ íŒŒì¼ì…ë‹ˆë‹¤.

ğŸ“Œ ì£¼ìš” ê¸°ëŠ¥:
- MIL(HDF5 ê¸°ë°˜) ë°ì´í„°ì…‹ ë¡œë”© ë° 5-Fold Cross Validation ë¶„í• 
- Spatial Constraint + Rank Constraint í¬í•¨í•œ AttriMIL ëª¨ë¸ í•™ìŠµ
- í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì • (ê°€ì¤‘ì¹˜ ì ìš©)
- ê²€ì¦ ê¸°ë°˜ Early Stopping ë° Best Model ì €ì¥
- í…ŒìŠ¤íŠ¸ ê²°ê³¼ AUC ë° í´ë˜ìŠ¤ë³„ Accuracy ì¶œë ¥

ì…ë ¥: í•™ìŠµìš© CSV + HDF5 feature íŒŒì¼ ê²½ë¡œ + Fold split CSV ê²½ë¡œ
ì¶œë ¥: foldë³„ ìµœì  ëª¨ë¸ (.pt) ë° í‰ê°€ ë¡œê·¸
"""

import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.nn import functional as F

from models.AttriMIL import AttriMIL  # AttriMIL ëª¨ë¸ ì •ì˜
from constraints import spatial_constraint, rank_constraint  # ì •ê·œí™” ì œì•½ í•¨ìˆ˜
from utils import get_split_loader, calculate_error  # ë°ì´í„° ë¡œë” ë° ìœ í‹¸ í•¨ìˆ˜
from dataloader import Generic_MIL_Dataset  # MIL ë°ì´í„°ì…‹ í´ë˜ìŠ¤

from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.metrics import auc as calc_auc

import numpy as np
import queue

# ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")  # GPU ì‚¬ìš© ì—¬ë¶€

label_dict = {'HGSC': 0, 'LGSC': 1, 'CC': 2, 'EC': 3, 'MC': 4}  # í´ë˜ìŠ¤ ë¼ë²¨ ë§¤í•‘
n_classes = 5  # í´ë˜ìŠ¤ ìˆ˜
feature_dim = 512  # feature dimension (ResNet18 ê¸°ë°˜)

# ì •í™•ë„ ê¸°ë¡ìš© í´ë˜ìŠ¤
class Accuracy_Logger:
    def __init__(self, n_classes):
        self.n_classes = n_classes
        self.initialize()

    def initialize(self):
        self.data = [{"count": 0, "correct": 0} for _ in range(self.n_classes)]

    def log(self, Y_hat, Y):
        Y_hat = int(Y_hat)
        Y = int(Y)
        self.data[Y]["count"] += 1
        self.data[Y]["correct"] += (Y_hat == Y)

    def get_summary(self, c):
        count = self.data[c]["count"]
        correct = self.data[c]["correct"]
        return None if count == 0 else correct / count, correct, count

# ì „ì²´ í•™ìŠµ ë£¨í”„ (5-Fold)
def train_attrimil(csv_path, h5_dir, split_path, save_path, max_epoch=200):
    dataset = Generic_MIL_Dataset(
        csv_path=csv_path,
        data_dir=h5_dir,
        shuffle=False,
        seed=7,
        print_info=True,
        label_dict=label_dict,
        patient_strat=False
    )

    for fold in range(5):  # 5ê°œ Fold í•™ìŠµ
        split_file = os.path.join(split_path, f"splits_{fold}.csv")
        train_set, val_set, test_set = dataset.return_splits(from_id=False, csv_path=split_file)

        model = AttriMIL(dim=feature_dim, n_classes=n_classes).to(device)  # ëª¨ë¸ ì´ˆê¸°í™”
        optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-4, momentum=0.9, weight_decay=1e-5)
        loss_fn = nn.CrossEntropyLoss(weight=calculate_class_weights(train_set, n_classes).to(device))  # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©

        label_positive_list = [queue.Queue(maxsize=4) for _ in range(n_classes)]  # ìˆœìœ„ì œì•½ìš© í
        label_negative_list = [queue.Queue(maxsize=4) for _ in range(n_classes)]

        train_loader = get_split_loader(train_set, training=True, testing=False, weighted=True)
        val_loader = get_split_loader(val_set, testing=False)
        test_loader = get_split_loader(test_set, testing=False)

        best_loss = float('inf')
        patience = 0  # Early stopping ìš©

        for epoch in range(max_epoch):
            model.train()
            total_loss = 0
            for data, label, coords, nearest in train_loader:
                data, label = data.to(device), label.to(device)

                # ëª¨ë¸ ì¶”ë¡  ë° ì†ì‹¤ ê³„ì‚°
                logits, _, _, attribute_score, _ = model(data)
                loss_bag = loss_fn(logits, label)
                loss_spa = spatial_constraint(attribute_score, n_classes, nearest, ks=3)
                loss_rank, label_positive_list, label_negative_list = rank_constraint(data, label, model, attribute_score, n_classes, label_positive_list, label_negative_list)

                loss = loss_bag + 1.0 * loss_spa + 5.0 * loss_rank  # ì´ ì†ì‹¤
                loss.backward()
                optimizer.step()
                optimizer.zero_grad()

                total_loss += loss.item()

            val_loss = validate(model, val_loader, loss_fn)  # ê²€ì¦ ì†ì‹¤ í‰ê°€
            if val_loss < best_loss:
                best_loss = val_loss
                patience = 0
                torch.save(model.state_dict(), os.path.join(save_path, f"fold{fold}_best.pt"))  # ëª¨ë¸ ì €ì¥
            else:
                patience += 1

            if patience > 20 and epoch > 50:
                print(f"Early stopping at epoch {epoch}")
                break

        model.load_state_dict(torch.load(os.path.join(save_path, f"fold{fold}_best.pt")))  # ìµœì  ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
        test_result(model, test_loader)  # í…ŒìŠ¤íŠ¸ í‰ê°€

# ê²€ì¦ ì†ì‹¤ ê³„ì‚°
def validate(model, loader, loss_fn):
    model.eval()
    loss_total = 0
    with torch.no_grad():
        for data, label, coords, nearest in loader:
            data, label = data.to(device), label.to(device)
            logits, _, _, _, _ = model(data)
            loss = loss_fn(logits, label)
            loss_total += loss.item()
    return loss_total / len(loader)

# í…ŒìŠ¤íŠ¸ í‰ê°€ ë° ì¶œë ¥
def test_result(model, loader):
    model.eval()
    logger = Accuracy_Logger(n_classes)
    all_probs = np.zeros((len(loader), n_classes))  # ì˜ˆì¸¡ í™•ë¥  ì €ì¥
    all_labels = np.zeros(len(loader))  # ì‹¤ì œ ë¼ë²¨ ì €ì¥

    for i, (data, label, coords, nearest) in enumerate(loader):
        data, label = data.to(device), label.to(device)
        with torch.no_grad():
            _, Y_prob, Y_hat, _, _ = model(data)

        logger.log(Y_hat, label)
        all_probs[i] = Y_prob.cpu().numpy()
        all_labels[i] = label.item()

    # AUC ë° í´ë˜ìŠ¤ë³„ ì •í™•ë„ ì¶œë ¥
    auc = roc_auc_score(label_binarize(all_labels, classes=list(range(n_classes))), all_probs, multi_class='ovr')
    print(f"Test AUC: {auc:.4f}")
    for c in range(n_classes):
        acc, correct, count = logger.get_summary(c)
        print(f"Class {c}: Acc={acc:.4f}, Correct={correct}/{count}")

# í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •ìš© ê°€ì¤‘ì¹˜ ê³„ì‚°
def calculate_class_weights(dataset, n_classes):
    labels = [label for label in dataset.labels]
    class_counts = np.bincount(labels, minlength=n_classes)
    class_weights = 1. / (class_counts + 1e-6)
    class_weights = class_weights * (len(labels) / np.sum(class_weights * class_counts))
    return torch.FloatTensor(class_weights)
